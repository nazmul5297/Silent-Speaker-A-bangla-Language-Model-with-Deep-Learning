Silent Speaker is an applied model of human-computer interaction. This model can be applied in
various vital applications like crime-fighting and helping the hearing-impaired. It consists of one
domains-Visual Speech Recognition. This project is made for recognizing speech without the presence or
support of any auditory signal. So far, a lot of research work has been done on lip-reading in English,
French, Chinese, and many languages. But there is little research work has done to recognize speech
from a silent video in the Bengali language. This thesis work provides a new approach to detect some
word of Bengali language using deep learning. In this project, we want to classify some words using our
own created dataset. We track the distance between the inner and outer lip and extract features for
LSTM and create our model that can classify the word. Our final accuracy is 43% and in the future, we
want to increase our dataset size and modification of our model in such a way that can produce more
accuracy.
